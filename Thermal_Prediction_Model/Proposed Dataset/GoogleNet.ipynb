{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec97a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "# === Focal Loss ===\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, weight=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logpt = nn.functional.log_softmax(input, dim=1)\n",
    "        pt = torch.exp(logpt)\n",
    "        logpt = (1 - pt) ** self.gamma * logpt\n",
    "        loss = nn.functional.nll_loss(logpt, target, weight=self.weight)\n",
    "        return loss\n",
    "\n",
    "# === Config ===\n",
    "data_dir = r\"C:\\Users\\assen\\Downloads\\My_preposed\\Preprocessed\"\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "patience = 7\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Transforms ===\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# === Dataset & Split ===\n",
    "dataset = datasets.ImageFolder(root=data_dir)\n",
    "targets = dataset.targets\n",
    "\n",
    "# Extract group ID from filename like 'P6_Sad_FLIR1001234_face1'\n",
    "group_labels = [os.path.basename(path).split('_')[0] for path, _ in dataset.samples]  # e.g., 'P6'\n",
    "groups = [int(label[1:]) for label in group_labels]  # remove 'P' and convert to int\n",
    "\n",
    "# Stratified Group K-Fold\n",
    "skf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_idx, val_idx = next(skf.split(np.zeros(len(targets)), targets, groups))\n",
    "\n",
    "train_dataset = copy.deepcopy(dataset)\n",
    "val_dataset = copy.deepcopy(dataset)\n",
    "train_dataset.samples = [dataset.samples[i] for i in train_idx]\n",
    "val_dataset.samples = [dataset.samples[i] for i in val_idx]\n",
    "train_dataset.targets = [targets[i] for i in train_idx]\n",
    "val_dataset.targets = [targets[i] for i in val_idx]\n",
    "train_dataset.transform = train_transform\n",
    "val_dataset.transform = val_transform\n",
    "\n",
    "# === Weighted Sampling ===\n",
    "class_counts = np.bincount(train_dataset.targets)\n",
    "sample_weights = [1.0 / class_counts[label] for label in train_dataset.targets]\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# === Dataloaders ===\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "# === Model ===\n",
    "model = models.googlenet(pretrained=True, aux_logits=True)  # use aux_logits=True for training\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.inception5b.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, len(dataset.classes))\n",
    "model.aux1.fc2 = nn.Linear(model.aux1.fc2.in_features, len(dataset.classes))\n",
    "model.aux2.fc2 = nn.Linear(model.aux2.fc2.in_features, len(dataset.classes))\n",
    "model = model.to(device)\n",
    "\n",
    "# === Loss, Optimizer, Scheduler ===\n",
    "criterion = FocalLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# === Training Loop ===\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "print(\"ðŸš€ Starting training...\\n\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, aux1, aux2 = model(images)\n",
    "\n",
    "        loss_main = criterion(outputs, labels)\n",
    "        loss_aux1 = criterion(aux1, labels)\n",
    "        loss_aux2 = criterion(aux2, labels)\n",
    "        loss = loss_main + 0.3 * loss_aux1 + 0.3 * loss_aux2\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # === Validation ===\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_loss /= total\n",
    "    val_acc = correct / total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"ðŸ“Š Epoch [{epoch+1}/{num_epochs}] | Train Loss: {train_loss:.4f}, Acc: {train_acc*100:.2f}% | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Acc: {val_acc*100:.2f}%\")\n",
    "\n",
    "    # === Checkpointing ===\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(model.state_dict(), \"best_googlenet_model.pth\")\n",
    "        print(\"âœ… Checkpoint saved.\")\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"ðŸ›‘ Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    scheduler.step()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# === Load Best Model ===\n",
    "model.load_state_dict(best_model_wts)\n",
    "\n",
    "# === Final Evaluation ===\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.tolist())\n",
    "        y_pred.extend(preds.cpu().tolist())\n",
    "\n",
    "final_acc = np.mean(np.array(y_true) == np.array(y_pred))\n",
    "print(f\"\\nâœ… Final Validation Accuracy: {final_acc*100:.2f}%\")\n",
    "print(\"\\nðŸ“Š Final Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred, target_names=dataset.classes))\n",
    "\n",
    "# === Plot Results ===\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title('Loss per Epoch')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Acc')\n",
    "plt.plot(val_accuracies, label='Val Acc')\n",
    "plt.title('Accuracy per Epoch')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
