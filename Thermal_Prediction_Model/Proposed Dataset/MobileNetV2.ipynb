{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ceacb8d",
   "metadata": {},
   "source": [
    "The Best Attained Accuracy Model For Proposed Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007609ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# ====================================================================\n",
    "# 1. CONFIGURATION\n",
    "# ====================================================================\n",
    "\n",
    "# --- Set this to the folder containing your emotion sub-folders ---\n",
    "DATASET_PATH = \"C:/Users/assen/Downloads/CROP/CROP/\" # Using the path from your screenshot\n",
    "\n",
    "# --- Model & Training Parameters ---\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16 # Can be increased slightly with efficient preprocessing\n",
    "NUM_CLASSES = 6\n",
    "EPOCHS = 25 # Let's train for a few more epochs as the model might learn more\n",
    "\n",
    "# ====================================================================\n",
    "# 2. ADVANCED PREPROCESSING FUNCTION\n",
    "# ====================================================================\n",
    "\n",
    "def preprocess_thermal_image(image_path, label):\n",
    "    \"\"\"\n",
    "    This function takes an image file path, loads it, resizes it, applies \n",
    "    Grayscale/CLAHE, and prepares it for the model.\n",
    "    \"\"\"\n",
    "    def _apply_preprocessing(path):\n",
    "        # Decode the path and read the image with OpenCV\n",
    "        path = path.numpy().decode('utf-8')\n",
    "        img_array = cv2.imread(path)\n",
    "        \n",
    "        # --- FIX: Resize is now done here using cv2 ---\n",
    "        # This ensures every image is the same size before other processing.\n",
    "        resized_img = cv2.resize(img_array, IMAGE_SIZE)\n",
    "        \n",
    "        # Perform all other operations on the already resized image\n",
    "        gray_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        enhanced_img = clahe.apply(gray_img)\n",
    "        final_img = cv2.cvtColor(enhanced_img, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        return final_img\n",
    "\n",
    "    # Apply the OpenCV function using tf.py_function\n",
    "    image = tf.py_function(_apply_preprocessing, [image_path], tf.uint8)\n",
    "    \n",
    "    # Now that the image is always 224x224, we just need to tell TensorFlow\n",
    "    # to trust us on the shape. This is crucial.\n",
    "    image.set_shape(IMAGE_SIZE + (3,))\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# ====================================================================\n",
    "# 3. LOAD AND PREPARE DATASET\n",
    "# ====================================================================\n",
    "\n",
    "print(f\"Loading images from: {DATASET_PATH}\")\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    raise FileNotFoundError(f\"Directory not found: {DATASET_PATH}\")\n",
    "\n",
    "# Create a dataset of all file paths\n",
    "full_dataset = tf.data.Dataset.list_files(os.path.join(DATASET_PATH, '*/*'), shuffle=True, seed=123)\n",
    "\n",
    "# Get class names from subdirectories\n",
    "class_names = np.array(sorted([item.name for item in os.scandir(DATASET_PATH) if item.is_dir()]))\n",
    "print(\"âœ… Found classes:\", list(class_names))\n",
    "\n",
    "def get_label(file_path):\n",
    "    # Extracts the parent directory name (e.g., 'Happy') and finds its index\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return tf.argmax(parts[-2] == class_names)\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # We pass the file_path itself to our preprocessing function\n",
    "    return file_path, label\n",
    "\n",
    "# Create a labeled dataset of (image_path, label_index)\n",
    "labeled_dataset = full_dataset.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# --- Split the data into training (80%) and validation (20%) sets ---\n",
    "DATASET_SIZE = tf.data.experimental.cardinality(labeled_dataset).numpy()\n",
    "train_size = int(0.8 * DATASET_SIZE)\n",
    "\n",
    "train_data = labeled_dataset.take(train_size)\n",
    "validation_data = labeled_dataset.skip(train_size)\n",
    "\n",
    "# --- Apply the new preprocessing and batch the data ---\n",
    "# This .map() call is where the magic happens!\n",
    "print(\"Applying advanced preprocessing to the dataset...\")\n",
    "train_dataset = train_data.map(preprocess_thermal_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "validation_dataset = validation_data.map(preprocess_thermal_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Configure dataset for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.batch(BATCH_SIZE).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"âœ… New preprocessing pipeline is ready!\")\n",
    "\n",
    "# ====================================================================\n",
    "# 4. BUILD, COMPILE, AND TRAIN THE MODEL (UNCHANGED)\n",
    "# ====================================================================\n",
    "\n",
    "# We use the exact same model architecture to ensure a fair comparison\n",
    "input_shape = IMAGE_SIZE + (3,)\n",
    "base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create the new model on top\n",
    "inputs = Input(shape=input_shape)\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(inputs) # Use the built-in preprocessing\n",
    "x = base_model(x, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "print(\"\\n--- Starting Training with Advanced Preprocessing ---\")\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "# ====================================================================\n",
    "# 5. EVALUATE AND VISUALIZE RESULTS\n",
    "# ====================================================================\n",
    "\n",
    "print(\"\\n--- Evaluating Final Model ---\")\n",
    "loss, accuracy = model.evaluate(validation_dataset)\n",
    "print(f\"\\nFinal Validation Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Final Validation Loss: {loss:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(EPOCHS), acc, label='Training Accuracy')\n",
    "plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(EPOCHS), loss, label='Training Loss')\n",
    "plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.suptitle('Model Training History with Advanced Preprocessing ðŸ“Š')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a86a402",
   "metadata": {},
   "source": [
    "Generating Confusion Matrix..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1370189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# 4. GENERATE REPORT AND CONFUSION MATRIX\n",
    "# ====================================================================\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"--- Generating Final Report ---\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# --- Get all predictions from the validation set ---\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "for images, labels in validation_dataset:\n",
    "    true_labels.extend(labels.numpy())\n",
    "    preds = model.predict(images, verbose=0)\n",
    "    predicted_labels.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "# --- Print the detailed Classification Report ---\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_names, labels=np.arange(NUM_CLASSES), zero_division=0))\n",
    "\n",
    "# --- Display the Confusion Matrix ---\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(true_labels, predicted_labels, labels=np.arange(NUM_CLASSES))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "disp.plot(ax=ax, cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
